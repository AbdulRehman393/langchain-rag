{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce965cf",
   "metadata": {},
   "source": [
    "## Preparing the documents and vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('rag_vs_fine_tuning.pdf')\n",
    "data = loader.load()\n",
    "\n",
    "# Split the document using RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50)\n",
    "docs = splitter.split_documents(data) \n",
    "\n",
    "# Embed the documents in a persistent Chroma vector database\n",
    "embedding_function = OpenAIEmbeddings(api_key='<OPENAI_API_TOKEN>', model='text-embedding-3-small')\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=os.getcwd()\n",
    ")\n",
    "\n",
    "# Configure the vector store as a retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e948f2",
   "metadata": {},
   "source": [
    "## Building a retrieval prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca313553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add placeholders to the message string\n",
    "message = \"\"\"\n",
    "Answer the following question using the context provided:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create a chat prompt template from the message string\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"human\", message)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1bc39d",
   "metadata": {},
   "source": [
    "## Creating a RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db26fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=OpenAIEmbeddings(api_key='<OPENAI_API_TOKEN>', model='text-embedding-3-small'),\n",
    "    persist_directory=os.getcwd()\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "# Create a chain to link retriever, prompt_template, and llm\n",
    "rag_chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | llm)\n",
    "\n",
    "# Invoke the chain\n",
    "response = rag_chain.invoke(\"Which popular LLMs were considered in the paper?\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
